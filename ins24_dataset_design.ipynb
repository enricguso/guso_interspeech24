{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77da5d49",
   "metadata": {},
   "source": [
    "# Meta-data generation script for Interspeech2024 speech enhancement dataset\n",
    "\n",
    "Define RIRs for the dataset. 60.000 utterances, 70% 15% 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979138dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import masp as srs\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import tqdm\n",
    "import librosa as lsa\n",
    "import scipy.signal as sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd415b8-086e-4716-aa81-18aadeb3a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_speechdirectivity(path, plot):\n",
    "    dirdata = scipy.io.loadmat(path)['azel_dir']\n",
    "    d = {}\n",
    "    bands = np.array(['100Hz', '125Hz', '160Hz', '200Hz', '250Hz', '315Hz', '400Hz', '500Hz', '630Hz', '800Hz', '1000Hz', '1250Hz', '1600Hz', '2000Hz', '2500Hz', '3150Hz', '4000Hz', '5000Hz', '6300Hz', '8000Hz', '10000Hz'])\n",
    "    for i, band in enumerate(bands):\n",
    "        d[band] = dirdata[i]\n",
    "    az_axis = np.linspace(-180, 175, 72)\n",
    "    el_axis = np.linspace(-90, 85, 36)\n",
    "    d['az_axis'] = az_axis\n",
    "    d['el_axis'] = el_axis\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,20))\n",
    "        for i, band in enumerate(bands):\n",
    "            plt.subplot(7,3,i+1)\n",
    "            plt.imshow(d[band], cmap='jet')\n",
    "            plt.yticks(range(len(d['el_axis']))[::8], [int(x) for x in d['el_axis'][::8]], fontsize=7)\n",
    "            plt.ylabel('elevation')\n",
    "            plt.xticks(range(len(d['az_axis']))[::8], [int(x) for x in d['az_axis'][::8]], rotation=90, fontsize=7)\n",
    "            plt.xlabel('azimuth')\n",
    "            plt.title(band)\n",
    "            plt.clim(-20,0)\n",
    "        cbar_ax = plt.gcf().add_axes([0.92, 0.15, 0.02, 0.72])  # [left, bottom, width, height]\n",
    "        cbar = plt.colorbar(cax=cbar_ax)\n",
    "        plt.savefig('speech_directivity.pdf')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebfe42-1f10-4d9a-8855-69fbabb4da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_speechdirectivity(path=pjoin('directivity_parsing_matlab', 'azel_dir.mat'), plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b18b9-8004-46d0-9b28-00a6c258c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_6band_rt60_vector():\n",
    "    np.random.seed() #we randomize so multiprocessing doesn't yield same RT60s\n",
    "    alphas = np.array([1.7196874268124676,\n",
    "                         1.6152228672267106,\n",
    "                         1.9318203836226113,\n",
    "                         2.55718115999814,\n",
    "                         4.176814897493042,\n",
    "                         2.4892656080814346])\n",
    "    betas = np.array([0.38685390302225775,\n",
    "                         0.24453641709737417,\n",
    "                         0.14321372785643122,\n",
    "                         0.10453218827453133,\n",
    "                         0.08678871224845529,\n",
    "                         0.18290733668646034])\n",
    "    sim_rt60Fs = []\n",
    "    for i in range(len(alphas)):\n",
    "        sim_rt60Fs.append(np.random.gamma(alphas[i], betas[i], 1))\n",
    "    return np.array(sim_rt60Fs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1f544-524c-475a-898d-7e1748799348",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt60s = []\n",
    "for i in range(60000):\n",
    "    rt60s.append(get_6band_rt60_vector())\n",
    "rt60s = np.array(rt60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45e6c8-4180-4346-8441-70a6e669d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt60s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129e419-4eb0-4cc6-aeef-2183b90d88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_centerfreqs = np.zeros((6))\n",
    "band_centerfreqs[0] = 125\n",
    "for nb in range(5):\n",
    "    band_centerfreqs[nb+1] = 2 * band_centerfreqs[nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a8968-df57-45d8-a939-fe84adb32ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rt60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0af2f-9fad-4823-8510-8474d2a8e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt60 = np.array([np.mean(x) for x in rt60s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43132af6-86cd-4ff9-b65b-6acb23cb60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rt60s[:, 0], 500, density=True,alpha=0.8);\n",
    "plt.hist(rt60s[:, 1], 500, density=True,alpha=0.8);\n",
    "plt.hist(rt60s[:, 2], 500, density=True,alpha=0.8);\n",
    "plt.hist(rt60s[:, 3], 500, density=True,alpha=0.8);\n",
    "plt.hist(rt60s[:, 4], 500, density=True,alpha=0.8);\n",
    "plt.hist(rt60s[:, 5], 500, density=True,alpha=0.8);\n",
    "plt.hist(rt60, 500, density=True, alpha=0.8);\n",
    "\n",
    "plt.legend([str(int(x))+'Hz' for x in band_centerfreqs] + ['mean'])\n",
    "#plt.title('RT60 histogram')\n",
    "plt.xlabel('RT60[s]')\n",
    "plt.ylabel('count')\n",
    "plt.xlim([0, 2])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cef8ee-c1f7-4849-a304-aa5f2535e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_echogram(anechoic_echogram):\n",
    "    nSrc = anechoic_echogram.shape[0]\n",
    "    nRec = anechoic_echogram.shape[1]\n",
    "    nBands = anechoic_echogram.shape[2]\n",
    "    # Returns the \"anechoic\" version of an echogram\n",
    "    # Should keep the receiver directivy\n",
    "    for src in range(nSrc):\n",
    "        for rec in range(nRec):\n",
    "            for band in range(nBands):\n",
    "                anechoic_echogram[src, rec, band].time = anechoic_echogram[src, rec, band].time[:2]\n",
    "                anechoic_echogram[src, rec, band].coords = anechoic_echogram[src, rec, band].coords[:2, :]\n",
    "                anechoic_echogram[src, rec, band].value = anechoic_echogram[src, rec, band].value[:2,:]\n",
    "                anechoic_echogram[src, rec, band].order = anechoic_echogram[src, rec, band].order[:2,:]\n",
    "    return anechoic_echogram\n",
    "def head_2_ku_ears(head_pos,head_orient):\n",
    "# based on head pos and orientation, compute coordinates of ears\n",
    "    ear_distance_ku100=0.0875\n",
    "    theta = (head_orient[0]) * np.pi / 180\n",
    "    R_ear = [head_pos[0] - ear_distance_ku100 * np.sin(theta),\n",
    "              head_pos[1] + ear_distance_ku100 * np.cos(theta), \n",
    "              head_pos[2]]\n",
    "    L_ear = [head_pos[0] + ear_distance_ku100 * np.sin(theta),\n",
    "              head_pos[1] - ear_distance_ku100 * np.cos(theta), \n",
    "              head_pos[2]]\n",
    "    return [L_ear,R_ear]\n",
    "    \n",
    "def plot_scene(room_dims,head_pos,head_orient,l_mic_pos,l_src_pos,perspective=\"xy\"):\n",
    "#   function to plot the designed scene\n",
    "#   room_dims - dimensions of the room [x,y,z]\n",
    "#   head_pos - head position [x,y,z]\n",
    "#   head_orient - [az,el]\n",
    "#   l_src_pos - list of source positions [[x,y,z],...,[x,y,z]]\n",
    "#   perspective - which two dimensions to show \n",
    "    if perspective==\"xy\":\n",
    "        dim1=1\n",
    "        dim2=0\n",
    "    elif perspective==\"yz\":\n",
    "        dim1=2\n",
    "        dim2=1\n",
    "    elif perspective==\"xz\":\n",
    "        dim1=2\n",
    "        dim2=0\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    plt.xlim((0,room_dims[dim1]))\n",
    "    plt.ylim((0,room_dims[dim2]))\n",
    "    plt.axvline(head_pos[dim1], color='y') # horizontal lines\n",
    "    plt.axhline(head_pos[dim2], color='y') # vertical lines\n",
    "    plt.grid(True)\n",
    "    # plot sources and receivers\n",
    "    plt.plot(head_pos[dim1],head_pos[dim2], \"o\", ms=10, mew=2, color=\"black\")\n",
    "    # plot ears\n",
    "    plt.plot(l_mic_pos[0][dim1],l_mic_pos[0][dim2], \"o\", ms=3, mew=2, color=\"blue\")# left ear in blue\n",
    "    plt.plot(l_mic_pos[1][dim1],l_mic_pos[1][dim2], \"o\", ms=3, mew=2, color=\"red\")# right ear in red\n",
    "\n",
    "    for i,src_pos in enumerate(l_src_pos):\n",
    "        plt.plot(src_pos[dim1],src_pos[dim2], \"o\", ms=10, mew=2, color=\"red\")\n",
    "        plt.annotate(str(i), (src_pos[dim1],src_pos[dim2]))\n",
    "    # plot head orientation if looking from above \n",
    "    if perspective==\"xy\":\n",
    "        plt.plot(head_pos[dim1],head_pos[dim2], marker=(1, 1, -head_orient[0]), ms=20, mew=2,color=\"black\")\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "\n",
    "def process(src, headC, headOrient, room, rt60, maxlim, ambi_order, fs_rir, decoder, speech):\n",
    "    \n",
    "    band_centerfreqs = np.empty(len(rt60))\n",
    "    if len(rt60) == 1:\n",
    "        band_centerfreqs = np.array([1000])\n",
    "    else:\n",
    "        band_centerfreqs[0] = 125\n",
    "        for nb in range(1, len(rt60)):\n",
    "            band_centerfreqs[nb] = 2 * band_centerfreqs[nb-1]\n",
    "    mic = np.array(head_2_ku_ears(headC,headOrient)) # we get BiMagLS mic points \n",
    "    mic = np.vstack((mic, headC)) # we add the head center microphone for MagLS decoders\n",
    "    nRec = mic.shape[0]\n",
    "    nSrc = src.shape[0]\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "    # Small correction for sound absorption coefficients:\n",
    "    if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "        abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "    # Generally, we simulate up to RT60:\n",
    "    limits = np.minimum(rt60, maxlim)\n",
    "    # Compute IRs with MASP at 48k:\n",
    "    abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, headOrient)\n",
    "    #ane_echograms = crop_echogram(copy.deepcopy(abs_echograms))\n",
    "    mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs_rir)/np.sqrt(4*np.pi)\n",
    "    #ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs_rir)/np.sqrt(4*np.pi)\n",
    "    # Pad anechoic rirs so we don't loose alignment when convolving\n",
    "    #zeros_to_pad = len(mic_rirs) - len(ane_rirs)\n",
    "    #zeros_to_pad = np.zeros((zeros_to_pad, mic_rirs.shape[1], mic_rirs.shape[2], mic_rirs.shape[3]))\n",
    "    #ane_rirs = np.concatenate((ane_rirs, zeros_to_pad))\n",
    "    bin_ir = np.array([sig.fftconvolve(np.squeeze(mic_rirs[:,:,0, 0]), decoder[:,:,0], 'full', 0).sum(1),\n",
    "                    sig.fftconvolve(np.squeeze(mic_rirs[:,:,1, 0]), decoder[:,:,1], 'full', 0).sum(1)])\n",
    "    #bin_aneIR = np.array([sig.fftconvolve(np.squeeze(ane_rirs[:,:,0, 0]), decoder[:,:,0], 'full', 0).sum(1),\n",
    "    #                sig.fftconvolve(np.squeeze(ane_rirs[:,:,1, 0]), decoder[:,:,1], 'full', 0).sum(1)])\n",
    "    reverberant_src = np.array([sig.fftconvolve(speech, bin_ir[0, :], 'same'), sig.fftconvolve(speech, bin_ir[1, :], 'same')])\n",
    "    #anechoic_src = np.array([sig.fftconvolve(speech, bin_aneIR[0, :], 'same'), sig.fftconvolve(speech, bin_aneIR[1, :], 'same')])\n",
    "    monoir = mic_rirs[:,:,2]\n",
    "    est_sb_rt60 = pra.experimental.rt60.measure_rt60(monoir[:,0,0], fs=fs_rir, decay_db=20, plot=False)\n",
    "    return reverberant_src, mic, np.array([est_sb_rt60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312508e-d6b7-4669-b7af-0a79ae3ab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_path = pjoin('decoders_ord10', 'Ku100_ALFE_Window_sinEQ_bimag.mat') #10th order BimagLS decoder del KU100 sin HA a 48kHz\n",
    "decoder = mat73.loadmat(decoder_path)['hnm']\n",
    "decoder = np.roll(decoder,500,axis=0)\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "\n",
    "headC_x = 2.0  \n",
    "headC_y = 2.0\n",
    "headC_z = 1.0\n",
    "headOrient_azi = 0.0\n",
    "headOrient_ele = 0.0\n",
    "headC = np.array([headC_x, headC_y, headC_z])\n",
    "headOrient = np.array([headOrient_azi,headOrient_ele])\n",
    "src = np.array([[3,\t3, 1]]) #speech speaker position following convention:\n",
    "\n",
    "room = np.array([6, 4, 2.5]) #dimensions\n",
    "rt60=np.array([0.01])\n",
    "fs_rir = 48000\n",
    "fs_target = fs_rir\n",
    "\n",
    "speech, fs_speech = lsa.load('ane_speech.wav', sr=fs_rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c8f7b-7002-4492-a0ec-e84959c5e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt60s = get_6band_rt60_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034eeff-3ba7-4fb5-aec8-ef998ffc251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716e42a-77fe-4c97-ac5c-b784aacc3f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headOrient = np.array([0.,0.])\n",
    "mic_rir = process(src, headC, headOrient, room, rt60s, maxlim, ambi_order, fs_rir, decoder, speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384ca2c-236a-4219-b6f0-2ee0eaef8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_sb_rt60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a58d3e-c4e9-46ec-8bac-e4a5d12d2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rt60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d24d7-919d-488d-a781-bd78d64ba10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(mb_rev, rate=fs_rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04070fa6-9abe-4f36-82e8-6954974602af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_rev, mic1, est_sb_rt60_new = process(src, headC, headOrient, room, np.array([np.mean(rt60s)]), maxlim, ambi_order, fs_rir, decoder, speech)\n",
    "#plot_scene(room,headC, headOrient,mic0,src,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c275896-096b-42c4-ae7a-ffcea91fb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sb_rev, rate=fs_rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ceab0-435c-4829-89a3-44c333dbe4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4591e4-bdb2-4a14-ad8d-321d3049d537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21862a4-fa13-467f-8e3b-895d3d05bce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891b011-ad0b-4cfa-b87e-36e50fd757a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_orient_azi = np.random.uniform(low = -45, high = 45, size = len(df))\n",
    "head_orient_ele = np.random.uniform(low = -10, high = 10, size = len(df))\n",
    "angle = np.random.uniform(low = -45, high = 45, size = len(df))\n",
    "dist = np.random.uniform(low = 0.5, high = 3, size = len(df))\n",
    "#snr = np.random.uniform(low = 0, high = 6, size = len(df))\n",
    "room_x = np.random.uniform(low = 3., high = 30., size = len(df))\n",
    "room_y = room_x * np.random.uniform(low=0.5, high=1, size=len(room_x)) #avoid tunnels\n",
    "room_z = np.random.uniform(low = 2.5, high = 5., size = len(df))\n",
    "#\n",
    "t60s =  np.random.uniform(low = .1, high = 1., size = len(df))\n",
    "t60s = np.sort(t60s)\n",
    "#\n",
    "volumes = room_x * room_y * room_z\n",
    "volumes = np.sort(volumes)\n",
    "dist = np.sort(dist)\n",
    "perm = np.random.permutation(len(volumes))\n",
    "room_x = room_x[perm]\n",
    "room_y = room_y[perm]\n",
    "room_z = room_z[perm]\n",
    "dist = dist[perm]\n",
    "t60s = t60s[perm]\n",
    "head_pos = []\n",
    "for k in range(len(room_x)):\n",
    "    head_pos.append(np.array([np.random.uniform(low = 0.35*room_x[k], high = 0.65*room_x[k]),\n",
    "                        np.random.uniform(low = 0.35*room_y[k], high = 0.65*room_y[k]),\n",
    "                        np.random.uniform(low = 1., high = 2.)]))\n",
    "head_pos = np.array(head_pos)\n",
    "room = np.array((room_x, room_y, room_z)).T\n",
    "target_pos = []\n",
    "for k in tqdm.tqdm(range(len(room_x))):\n",
    "    target_pos.append(hlp.place_on_circle_in_room(head_pos[k], dist[k], \n",
    "                                                               angle[k]+head_orient_azi[k], room[k]))\n",
    "target_pos = np.squeeze(np.array(target_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a66d9-6e47-4f22-b928-b902807b9e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0b61a-b0e3-4cc7-9cab-f0b30a4c0d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21b608-7020-4593-9863-80a1e2edc626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08830e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks:\n",
    "np.all(target_pos < room) # all targets are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(head_pos < room) # all heads are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's check the ears:\n",
    "ears_pos = []\n",
    "for k in range(head_pos.shape[0]):\n",
    "    ears_pos.append(np.array(hlp.head_2_ku_ears(head_pos[k], np.array([head_orient_azi[k],head_orient_ele[k]]))))\n",
    "\n",
    "ears_pos = np.array(ears_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e078be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos[:, 0, :] < room) # all left ears are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos[:, 1, :] < room) # all right are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5550b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final MINIMUM distance between head and target (check we don't have an intra-craneal target)\n",
    "min(np.sqrt(np.sum((target_pos - head_pos)**2, axis=1))) > 0.0875 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a36857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance of ears against a wall\n",
    "min ( min(room[:, 0] - ears_pos[:, 0, 0]), min(room[:, 0] - ears_pos[:, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd075f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "min ( min(room[:, 1] - ears_pos[:, 0, 1]), min(room[:, 1] - ears_pos[:, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "min ( min(room[:, 2] - ears_pos[:, 0, 2]), min(room[:, 2] - ears_pos[:, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance of targets against a wall\n",
    "min(min(room[:, 0] - target_pos[:, 0]), min(room[:, 1] - target_pos[:, 1]), min(room[:, 2] - target_pos[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61390f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'split': 'mls_split'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(14, \"room_x\", room[:, 0])\n",
    "df.insert(15, \"room_y\", room[:, 1])\n",
    "df.insert(16, \"room_z\", room[:, 2])\n",
    "df.insert(17, \"rt60\", t60s)\n",
    "df.insert(18, \"headC_x\", head_pos[:,0])\n",
    "df.insert(19, \"headC_y\", head_pos[:,1])\n",
    "df.insert(20, \"headC_z\", head_pos[:,2])\n",
    "df.insert(21, \"src_x\", target_pos[:,0])\n",
    "df.insert(22, \"src_y\", target_pos[:,1])\n",
    "df.insert(23, \"src_z\", target_pos[:,2])\n",
    "df.insert(24, \"headOrient_azi\", head_orient_azi)\n",
    "df.insert(25, \"headOrient_ele\", head_orient_ele)\n",
    "df.insert(26, \"snr\", snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76109516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['idx'] = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f31f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# generate a figure for each situation:\n",
    "for k in tqdm.tqdm(range(head_pos.shape[0])):\n",
    "    hlp.plot_scene(room[k], head_pos[k], np.array([head_orient_azi[k], head_orient_ele[k]])\n",
    "                   , ears_pos[k],[target_pos[k]], perspective=\"xy\")\n",
    "    plt.title(str(head_orient_azi[k])+ '_' + str(angle[k]))\n",
    "    plt.savefig(pjoin('situation_plots_rot', os.path.splitext(os.path.basename(df.iloc[k].audio_path))[0]+'.pdf'))\n",
    "    plt.close('all')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('meta_microson_v1.csv', index=False, compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cb9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
